# ğŸ§  LLM UI â€” Local Chat Interface with Ollama + Mistral

A full-stack conversational AI interface using:

- âš›ï¸ **React + Tailwind CSS** frontend
- ğŸŸ© **Node.js + Express** backend (streaming proxy)
- ğŸ¤– **Ollama** running Mistral locally as the LLM model

---

## ğŸ“¦ Features

- Real-time token-by-token streaming (like ChatGPT)
- Clean chat UI with message bubbles
- Abort/resume generation support
- Local-first privacy with Ollama

---

## ğŸ§° Stack

| Layer      | Tech                  |
| ---------- | --------------------- |
| Frontend   | React, Vite, Tailwind |
| Backend    | Node.js, Express      |
| LLM Engine | Ollama + Mistral      |

---

## ğŸš€ Getting Started

### 1. Clone the Repo

```bash
git clone git@github.com:sijoyjos/llm-ui.git
cd llm-ui
```

---

### 2. Setup Backend

```bash
cd backend
npm install
node index.js
```

> Ensure Ollama is running and mistral model is pulled:
>
> ```bash
> ollama run mistral
> ```

This will serve the local LLM on:  
`http://localhost:11434`

---

### 3. Setup Frontend

```bash
cd ../frontend
npm install
npm run dev
```

Then open: [http://localhost:5173](http://localhost:5173)

---

## âœ¨ Sample Prompt

```
Explain how Server-Sent Events work in Node.js and when youâ€™d use them.
```

---

## ğŸ“ Folder Structure

```
llm-ui/
â”œâ”€â”€ backend/       # Node.js API proxy to Ollama
â”‚   â””â”€â”€ index.js
â”œâ”€â”€ frontend/      # React + Tailwind chat UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â””â”€â”€ ChatStream.jsx
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ”’ Privacy First

This project uses **Ollama locally**, so:

- No prompts or responses leave your machine
- Ideal for secure, private LLM experimentation
- Great for air-gapped or dev environments

---

## ğŸ’¡ Future Enhancements

- [ ] Markdown/code block rendering
- [ ] Chat history with localStorage
- [ ] File upload & prompt chaining
- [ ] Plugin-style assistant tools

---

## ğŸ“œ License

MIT â€” feel free to use, remix, and build on top of it!

---
